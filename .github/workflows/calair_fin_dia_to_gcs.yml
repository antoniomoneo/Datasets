name: CalAIR fin de d√≠a ‚Üí GCS (latest.flat.csv p√∫blico)

on:
  workflow_dispatch:
    inputs:
      date:
        description: "Fecha YYYY-MM-DD (opcional; por defecto ayer, Europe/Madrid)"
        required: false
  schedule:
    - cron: "15 2 * * *"  # 02:15 UTC ‚âà 04:15 Madrid

env:
  GCP_PROJECT_ID: aire-470107
  GCS_BUCKET: aire-470107-datasets-usw1

jobs:
  fetch-and-upload:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install requests

      - name: Auth to GCP
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Setup gcloud (gsutil)
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.GCP_PROJECT_ID }}

      - name: Run script (fin de d√≠a)
        id: run
        shell: bash
        run: |
          set -e
          if [ -n "${{ github.event.inputs.date }}" ]; then
            python ./scripts/fetch_calair_fin_dia.py --date "${{ github.event.inputs.date }}"
            TARGET_DIR="data/calair/${{ github.event.inputs.date }}"
          else
            python ./scripts/fetch_calair_fin_dia.py
            TARGET_DIR=$(find data/calair -mindepth 1 -maxdepth 1 -type d -printf '%T@ %p\n' | sort -nr | head -n1 | cut -d' ' -f2-)
            if [ -z "$TARGET_DIR" ]; then
              echo "‚ùå No se encontr√≥ ning√∫n directorio en data/calair/"
              exit 1
            fi
          fi
          echo "TARGET_DIR=$TARGET_DIR" >> $GITHUB_ENV
          echo "Contenido de $TARGET_DIR:"
          ls -la "$TARGET_DIR"

      - name: Reset prefix y publicar SOLO latest.flat.csv (p√∫blico + no-cache)
        shell: bash
        run: |
          set -e
          echo "üóëÔ∏è Borrando datasets antiguos en gs://${{ env.GCS_BUCKET }}/calair/ ..."
          if ! gsutil -m rm -r -f gs://${{ env.GCS_BUCKET }}/calair/**; then
            echo "‚ö†Ô∏è No se pudieron borrar datasets antiguos (puede que no existan)"
          fi

          echo "üìå Detectando el .flat.csv m√°s reciente..."
          LATEST_FLAT_LOCAL=$(find "$TARGET_DIR" -maxdepth 1 -type f -name 'calair_fin_dia_*.flat.csv' | sort | tail -n1)
          if [ -z "$LATEST_FLAT_LOCAL" ]; then
            echo "‚ùå No se encontr√≥ ning√∫n .flat.csv en $TARGET_DIR"
            exit 1
          fi
          cp "$LATEST_FLAT_LOCAL" "$TARGET_DIR/latest.flat.csv"

          echo "‚¨ÜÔ∏è Subiendo latest.flat.csv..."
          DEST="gs://${{ env.GCS_BUCKET }}/calair/latest.flat.csv"
          gsutil -m cp "$TARGET_DIR/latest.flat.csv" "$DEST"

          echo "üîì Haciendo p√∫blico SOLO ese objeto (ACL AllUsers:R)..."
          # En buckets con Uniform Bucket-Level Access este comando fallar√°; en ese caso, concede IAM allUsers:objectViewer al bucket una vez.
          if ! gsutil acl ch -u AllUsers:R "$DEST"; then
            echo "‚ö†Ô∏è No se pudo aplicar ACL; si el bucket usa UBLA, otorga IAM allUsers:objectViewer"
          fi

          echo "üö´ Deshabilitando cach√© para evitar stale en AI Studio..."
          gsutil -m setmeta -h "Cache-Control:no-cache, max-age=0" "$DEST"

          echo "‚úÖ Publicado:"
          gsutil ls -lh "$DEST"
          echo "üåê URL p√∫blica (si ACL correcto):"
          echo "https://storage.googleapis.com/${{ env.GCS_BUCKET }}/calair/latest.flat.csv"
